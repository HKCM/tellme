---
tags: ["缓存淘汰策略"]
---
# 缓存淘汰策略
---
## 缓存淘汰策略

- **内存淘汰：** redis自动进行，当redis内存达到设定的max-memery的时候，会自动触发淘汰机制，淘汰掉一些不重要的数据(可以自己设置策略方式)
- **超时剔除：** 当给redis设置了过期时间ttl之后，redis会将超时的数据进行删除
- **主动更新：** 可以手动调用方法把缓存删掉，通常用于解决缓存和数据库不一致问题

Redis共支持八种淘汰策略,大致分为三类:

1. 不淘汰
   1. noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键,无法解决缓存污染问题。一般生产环境不建议使用
2. 对设置了过期时间的数据中进行淘汰
   1. volatile-random：从配置了过期时间的键中进行随机删除。可能依然会存在缓存污染现象，无法解决缓存污染问题
   2. volatile-lfu：从配置了过期时间的键中驱逐使用频率最少的键
   3. volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键
   4. volatile-lru：从配置了过期时间的键中驱逐最久没有使用的键
3. 全部数据进行淘汰
   1. allkeys-random：从所有键值对中随机选择并删除数据,无法解决缓存污染问题
   2. allkeys-lru：从所有键值对中通过LRU算法驱逐最久没有使用的键
   3. allkeys-lfu：从所有键值对中驱逐使用频率最少的键

LRU 算法的全称是 Least Recently Used,按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。

LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。

---

### LRU算法

LRU 算法的全称是 Least Recently Used,按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。

Redis会记录每个数据的最近一次被访问的时间戳。在Redis在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。

接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。通过随机读取待删除集合，可以让Redis不用维护一个巨大的链表，也不用操作链表，进而提升性能。

Redis 选出的数据个数 N，通过配置参数 `maxmemory-samples` 进行配置。个数N越大，则候选集合越大，选择到的最久未被使用的就更准确，N越小，选择到最久未被使用的数据的概率也会随之减小

### LFU算法

LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。

当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 

Redis的LFU算法实现:当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。

Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这样在访问快速的情况下，如果每次被访问就将访问次数加一，很快某条数据就达到最大值255，可能很多数据都是255，那么退化成LRU算法了。

所以Redis为了解决这个问题，实现了一个更优的计数规则，并可以通过配置项，来控制计数器增加的速度。

- lfu-log-factor: 用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。
- lfu-decay-time: 控制访问次数衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。
- lfu-log-factor: 设置越大，递增概率越低，lfu-decay-time设置越大，衰减速度会越慢。

在应用 LFU 策略时，一般可以将 lfu_log_factor 取值为 10。 如果业务应用中有短时高频访问的数据的话，建议把 lfu_decay_time 值设置为 1。可以快速衰减访问次数。

